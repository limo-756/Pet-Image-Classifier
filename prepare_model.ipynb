{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:27.916354427Z",
     "start_time": "2026-02-21T11:44:27.904263589Z"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:27.984452Z",
     "iopub.status.busy": "2026-02-22T11:46:27.984292Z",
     "iopub.status.idle": "2026-02-22T11:46:35.446283Z",
     "shell.execute_reply": "2026-02-22T11:46:35.445672Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from pandas import DataFrame\n",
    "import io\n",
    "import contextlib\n",
    "import cv2 as cv\n",
    "from scipy.stats import skew\n",
    "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern, hog\n",
    "from skimage.measure import shannon_entropy\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from joblib import Parallel, delayed\n",
    "from cuml.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from cuml.neighbors import KNeighborsClassifier\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "import cv2\n",
    "from PIL import Image, ImageFile\n",
    "import cupy as cp\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53eaffa70c04c703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:27.962708146Z",
     "start_time": "2026-02-21T11:44:27.917172464Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.448008Z",
     "iopub.status.busy": "2026-02-22T11:46:35.447744Z",
     "iopub.status.idle": "2026-02-22T11:46:35.450747Z",
     "shell.execute_reply": "2026-02-22T11:46:35.450121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Default Configuration\n",
    "CONFIG = {\n",
    "    'normalization': 'standard', # options: 'standard', 'minmax'\n",
    "    'resize_dim': (224, 224),\n",
    "    'n_jobs': -1,\n",
    "\n",
    "    'lbp_radius': 3,\n",
    "    'lbp_points': 8,\n",
    "\n",
    "    'gabor': {\n",
    "        'ksize': 31, # Increased for better texture capture\n",
    "        'sigma': 4.0,\n",
    "        'theta': 0,\n",
    "        'lamda': 10.0,\n",
    "        'gamma': 0.5,\n",
    "        'phi': 0\n",
    "    },\n",
    "\n",
    "    'contour': {\n",
    "        'count' : 3,\n",
    "    },\n",
    "\n",
    "    'lucas_kanade': {\n",
    "        'max_corners': 20,\n",
    "        'quality_level': 0.01,\n",
    "        'min_distance': 10,\n",
    "        'block_size': 7\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf53d07fd9a5bbc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:28.010719331Z",
     "start_time": "2026-02-21T11:44:27.963382979Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.451759Z",
     "iopub.status.busy": "2026-02-22T11:46:35.451669Z",
     "iopub.status.idle": "2026-02-22T11:46:35.465893Z",
     "shell.execute_reply": "2026-02-22T11:46:35.465539Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeatureExtractor:\n",
    "\n",
    "    def __init__(self, config: dict):\n",
    "        self.config = config\n",
    "        if self.config.get('normalization') == 'standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        else:\n",
    "            self.scaler = MinMaxScaler()\n",
    "\n",
    "        g_params = self.config['gabor']\n",
    "        self.gabor_kernel = cv.getGaborKernel(\n",
    "            (int(g_params['ksize']), int(g_params['ksize'])),\n",
    "            float(g_params['sigma']),\n",
    "            float(g_params['theta']),\n",
    "            float(g_params['lamda']),\n",
    "            float(g_params['gamma']),\n",
    "            float(g_params['phi']),\n",
    "            ktype=cv.CV_32F\n",
    "        )\n",
    "\n",
    "\n",
    "    def _get_color_features(self, image) -> dict:\n",
    "        hsv_image = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "        rgb_image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        features = {}\n",
    "\n",
    "        # RGB Histogram\n",
    "        for i, color in enumerate(['red', 'blue', 'green']):\n",
    "            channel = rgb_image[:,:,i]\n",
    "            hist, _ = np.histogram(channel.ravel(), bins=10, range=(0, 256))\n",
    "            hist = hist.astype('float')\n",
    "            hist /= (hist.sum() + 1e-7)\n",
    "            for j in range(len(hist)):\n",
    "                features[f'{color}_{j}'] = float(hist[j])\n",
    "\n",
    "        for i, color in enumerate(['h', 's', 'v']):\n",
    "            channel = hsv_image[:,:,i]\n",
    "            mean = np.mean(channel)\n",
    "            std = np.std(channel)\n",
    "            features[f'moments_{color}_mean'] = float(mean)\n",
    "            features[f'moments_{color}_std'] = float(std)\n",
    "\n",
    "            if std > 1e-6:\n",
    "                skew_val = skew(channel.flatten())\n",
    "                features[f'moments_skew_{color}'] = float(0 if np.isnan(skew_val) else skew_val)\n",
    "            else:\n",
    "                features[f'moments_skew_{color}'] = float(0)\n",
    "\n",
    "        avg_rgb = np.mean(rgb_image, axis=(0, 1))\n",
    "        features['avg_red'] = float(avg_rgb[0])\n",
    "        features['avg_green'] = float(avg_rgb[1])\n",
    "        features['avg_blue'] = float(avg_rgb[2])\n",
    "        return features\n",
    "\n",
    "    def _get_frame_glcm_features(self, grey_frame):\n",
    "        features = {}\n",
    "        # Using fewer distances/angles for efficiency while capturing texture\n",
    "        distances = [1, 3]\n",
    "        angles = [0, np.pi/2] # Horizontal and Vertical\n",
    "\n",
    "        # GLCM requires integer types\n",
    "        grey_frame_int = (grey_frame).astype(np.uint8)\n",
    "\n",
    "        glcm = graycomatrix(grey_frame_int, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "\n",
    "        props = ['contrast', 'dissimilarity', 'homogeneity', 'correlation', 'energy']\n",
    "        for prop in props:\n",
    "            val = graycoprops(glcm, prop).ravel()\n",
    "            # Average over all distances/angles to reduce feature dimensionality\n",
    "            features[f'glcm_{prop}_mean'] = float(np.mean(val))\n",
    "            features[f'glcm_{prop}_std'] = float(np.std(val))\n",
    "\n",
    "        features['glcm_entropy'] = float(shannon_entropy(grey_frame))\n",
    "        return features\n",
    "\n",
    "    def _lbp_features(self, grey_frame):\n",
    "        # LBP usually on integer images? scikit-image handles float but warns.\n",
    "        # Ensure it works.\n",
    "        lbp = local_binary_pattern(grey_frame, self.config['lbp_points'], self.config['lbp_radius'], method='uniform')\n",
    "        # Uniform LBP histogram\n",
    "        n_bins = self.config['lbp_points'] + 2\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "        hist = hist.astype('float')\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "\n",
    "        features = {}\n",
    "        for i in range(len(hist)):\n",
    "            features[f'lbp_{i}'] = float(hist[i])\n",
    "        return features\n",
    "\n",
    "    def _get_gabor_features(self, grey_frame):\n",
    "        gabor_features = cv.filter2D(grey_frame, cv.CV_32F, self.gabor_kernel)\n",
    "\n",
    "        mean = float(np.mean(gabor_features))\n",
    "        std = float(np.std(gabor_features))\n",
    "        features = {\n",
    "            'gabor_mean': mean,\n",
    "            'gabor_std': std\n",
    "        }\n",
    "        return features\n",
    "\n",
    "    def _get_canny_features(self, grey_frame):\n",
    "        sigma = 0.33\n",
    "        v = np.median(grey_frame)\n",
    "        lower = int(max(0, (1.0 - sigma) * v))\n",
    "        upper = int(min(255, (1.0 + sigma) * v))\n",
    "        edges = cv.Canny(grey_frame, lower, upper)\n",
    "\n",
    "        # Edge density\n",
    "        edge_density = float(np.sum(edges > 0) / (edges.shape[0] * edges.shape[1]))\n",
    "        features = {'canny_edge_density': edge_density}\n",
    "        return features\n",
    "\n",
    "    def _get_contour_features(self, grey_frame):\n",
    "        # Binary threshold\n",
    "        _, img_th = cv.threshold(grey_frame, 127, 255, cv.THRESH_BINARY)\n",
    "        contours, _ = cv.findContours(img_th, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        features = {}\n",
    "        count = self.config['contour']['count']\n",
    "\n",
    "        # Sort by area\n",
    "        sorted_contours = sorted(contours, key=cv.contourArea, reverse=True)\n",
    "\n",
    "        for i in range(count):\n",
    "            if i < len(sorted_contours):\n",
    "                c = sorted_contours[i]\n",
    "                area = cv.contourArea(c)\n",
    "                perimeter = cv.arcLength(c, True)\n",
    "                if perimeter == 0: perimeter = 1e-7\n",
    "                circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "\n",
    "                features[f'contour_{i}_area'] = float(area)\n",
    "                features[f'contour_{i}_circularity'] = float(circularity)\n",
    "            else:\n",
    "                features[f'contour_{i}_area'] = 0.0\n",
    "                features[f'contour_{i}_circularity'] = 0.0\n",
    "        return features\n",
    "\n",
    "    def _get_hog_features(self, grey_frame):\n",
    "        # Using smaller image for HOG to reduce dimensions\n",
    "        features = {}\n",
    "        small = cv.resize(grey_frame, (64, 64))\n",
    "        hog_feats = hog(small, orientations=9, pixels_per_cell=(16, 16), cells_per_block=(2, 2), block_norm='L2-Hys')\n",
    "\n",
    "        # Statistical summary of HOG\n",
    "        features['hog_mean'] = float(np.mean(hog_feats))\n",
    "        features['hog_std'] = float(np.std(hog_feats))\n",
    "        features['hog_max'] = float(np.max(hog_feats))\n",
    "        return features\n",
    "\n",
    "    def _extract_features(self, row: dict) -> dict:\n",
    "        # print(f\"Processing image {row['index']}\")\n",
    "        image_path = row['image']\n",
    "        image_id = int(row['index'])\n",
    "        image = cv.imread(image_path)\n",
    "        grey_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        features = {'image_id': image_id, 'encoded_label': int(row['encoded_label'])}\n",
    "        features.update(self._get_color_features(image))\n",
    "        features.update(self._get_frame_glcm_features(grey_image))\n",
    "        features.update(self._lbp_features(grey_image))\n",
    "        features.update(self._get_gabor_features(grey_image))\n",
    "        features.update(self._get_canny_features(grey_image))\n",
    "        features.update(self._get_contour_features(grey_image))\n",
    "        features.update(self._get_hog_features(grey_image))\n",
    "        return features\n",
    "\n",
    "    def process_dataset(self, df: DataFrame, is_test: bool) -> (DataFrame, DataFrame):\n",
    "        print(f\"Processing {len(df)} images with {self.config['n_jobs']} jobs...\")\n",
    "        rows = df.reset_index().to_dict('records')\n",
    "\n",
    "        # Using joblib backend 'threading' might be safer for OpenCV which releases GIL?\n",
    "        # But 'loky' (default) is safer for process isolation.\n",
    "        nested_results = Parallel(n_jobs=self.config['n_jobs'])(delayed(self._extract_features)(row) for row in rows)\n",
    "\n",
    "        feature_df = pd.DataFrame(nested_results)\n",
    "\n",
    "        feature_names = [col for col in feature_df.columns if col not in ['image_id', 'encoded_label']]\n",
    "        print(f\"Df shape: {feature_df.shape}\")\n",
    "        print(f\"Df columms: {feature_df.columns}\")\n",
    "        print(f\"Feature names: {feature_names}\")\n",
    "        # Fill NaNs\n",
    "        feature_df[feature_names] = feature_df[feature_names].fillna(0)\n",
    "        feature_df[feature_names] = feature_df[feature_names].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "        if is_test:\n",
    "            feature_df[feature_names] = self.scaler.transform(feature_df[feature_names])\n",
    "        else:\n",
    "            feature_df[feature_names] = self.scaler.fit_transform(feature_df[feature_names])\n",
    "\n",
    "        y_df = feature_df[['encoded_label']]\n",
    "        feature_df = feature_df.drop(['encoded_label', 'image_id'], axis=1)\n",
    "        return feature_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d34ced8507e9117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:28.073069877Z",
     "start_time": "2026-02-21T11:44:28.012952341Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.467021Z",
     "iopub.status.busy": "2026-02-22T11:46:35.466929Z",
     "iopub.status.idle": "2026-02-22T11:46:35.470103Z",
     "shell.execute_reply": "2026-02-22T11:46:35.469569Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_svm_optuna(X_train, y_train, X_val, y_val, trials=20):\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'C': trial.suggest_float('C', 1e-2, 1e2, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 1e-3, 1e1, log=True),\n",
    "            'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "        }\n",
    "\n",
    "        clf = SVC(**params, probability=True)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        return acc\n",
    "\n",
    "    print(\"Optimizing SVM...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "\n",
    "    print(\"Best params (SVM):\", study.best_params)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b17d0c411922c22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:28.137795763Z",
     "start_time": "2026-02-21T11:44:28.077685361Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.471041Z",
     "iopub.status.busy": "2026-02-22T11:46:35.470955Z",
     "iopub.status.idle": "2026-02-22T11:46:35.474194Z",
     "shell.execute_reply": "2026-02-22T11:46:35.473733Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_rf_optuna(X_train, y_train, X_val, y_val, trials=20):\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        }\n",
    "\n",
    "        clf = RandomForestClassifier(**params, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        return acc\n",
    "\n",
    "    print(\"Optimizing Random Forest...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "\n",
    "    print(\"Best params (RF):\", study.best_params)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc82f949574ec98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:28.196978198Z",
     "start_time": "2026-02-21T11:44:28.140921627Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.475142Z",
     "iopub.status.busy": "2026-02-22T11:46:35.475055Z",
     "iopub.status.idle": "2026-02-22T11:46:35.478281Z",
     "shell.execute_reply": "2026-02-22T11:46:35.477784Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_knn_optuna(X_train, y_train, X_val, y_val, trials=20):\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_neighbors': trial.suggest_int('n_neighbors', 3, 20),\n",
    "            'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "            'metric': trial.suggest_categorical('metric', ['euclidean', 'manhattan']),\n",
    "        }\n",
    "\n",
    "        clf = KNeighborsClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        preds = clf.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        return acc\n",
    "\n",
    "    print(\"Optimizing KNN...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "\n",
    "    print(\"Best params (KNN):\", study.best_params)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b85b17a7a6d1f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:28.266727829Z",
     "start_time": "2026-02-21T11:44:28.211765248Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.479174Z",
     "iopub.status.busy": "2026-02-22T11:46:35.479088Z",
     "iopub.status.idle": "2026-02-22T11:46:35.483443Z",
     "shell.execute_reply": "2026-02-22T11:46:35.482956Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Pillow can recover from some truncated JPEGs\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "JPEG_BAD_PATTERNS = (\n",
    "    \"Corrupt JPEG data\",\n",
    "    \"Warning: unknown JFIF revision number\",\n",
    ")\n",
    "\n",
    "\n",
    "def image_is_corrupted(path: str) -> bool:\n",
    "    if not path or not os.path.isfile(path):\n",
    "        return True  # treat missing as bad\n",
    "\n",
    "    # Read raw bytes first (lets us use imdecode)\n",
    "    data = np.fromfile(path, dtype=np.uint8)\n",
    "    if data.size == 0:\n",
    "        return True\n",
    "\n",
    "\n",
    "    stderr_buf = io.StringIO()\n",
    "    with contextlib.redirect_stderr(stderr_buf):\n",
    "        img = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
    "\n",
    "    stderr_text = stderr_buf.getvalue()\n",
    "\n",
    "    # Drop if decode failed OR if libjpeg complained\n",
    "    if img is None or img.size == 0:\n",
    "        return True\n",
    "\n",
    "    if any(pat in stderr_text for pat in JPEG_BAD_PATTERNS):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(\"./dataset/splits/train.csv\", index_col='index')\n",
    "    val_df = pd.read_csv(\"./dataset/splits/validation.csv\", index_col='index')\n",
    "    test_df = pd.read_csv(\"./dataset/splits/test.csv\", index_col='index')\n",
    "    train_df = train_df[~train_df['image'].apply(image_is_corrupted)]\n",
    "    test_df = test_df[~test_df['image'].apply(image_is_corrupted)]\n",
    "    val_df = val_df[~val_df['image'].apply(image_is_corrupted)]\n",
    "\n",
    "    train_df = train_df.sample(n=1000, random_state=42)\n",
    "    val_df = val_df.sample(n=200, random_state=42)\n",
    "    test_df = test_df.sample(n=200, random_state=42)\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6978e8e10c09d577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:28.312791863Z",
     "start_time": "2026-02-21T11:44:28.267491789Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.484877Z",
     "iopub.status.busy": "2026-02-22T11:46:35.484780Z",
     "iopub.status.idle": "2026-02-22T11:46:35.487546Z",
     "shell.execute_reply": "2026-02-22T11:46:35.487099Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, title, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, filename))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9908e2146162f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:28.380713756Z",
     "start_time": "2026-02-21T11:44:28.313675152Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.488900Z",
     "iopub.status.busy": "2026-02-22T11:46:35.488809Z",
     "iopub.status.idle": "2026-02-22T11:46:35.492443Z",
     "shell.execute_reply": "2026-02-22T11:46:35.491940Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(clf, X_test, y_test, labels, filename):\n",
    "    try:\n",
    "        y_score = clf.predict_proba(X_test)\n",
    "        if len(y_score.shape) > 1 and y_score.shape[1] == 2:\n",
    "            y_score = y_score[:, 1]\n",
    "    except:\n",
    "        try:\n",
    "             y_score = clf.decision_function(X_test)\n",
    "        except:\n",
    "            print(\"Model does not support probability/decision function. Skipping ROC.\")\n",
    "            return\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, filename))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a3baef4f87ac59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:44:28.438484974Z",
     "start_time": "2026-02-21T11:44:28.381619602Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.493867Z",
     "iopub.status.busy": "2026-02-22T11:46:35.493776Z",
     "iopub.status.idle": "2026-02-22T11:46:35.523156Z",
     "shell.execute_reply": "2026-02-22T11:46:35.522655Z"
    }
   },
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image']\n",
    "        label = self.df.loc[idx, 'encoded_label']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.act1(self.conv1(x)))\n",
    "        x = self.pool2(self.act2(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.act3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train_cnn(train_df, val_df, epochs=5, lr=0.001, batch_size=32, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    print(f\"Training CNN on {device}...\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(CONFIG['resize_dim']),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = PetDataset(train_df, transform)\n",
    "    val_dataset = PetDataset(val_df, transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = SimpleCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_acc = correct / total\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "    # Plot loss curve\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('CNN Loss Curve')\n",
    "    loss_curve_path = os.path.join(OUTPUT_DIR, \"cnn_loss_curve.png\")\n",
    "    plt.savefig(loss_curve_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(OUTPUT_DIR, \"simple_cnn.pt\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    return model_path, loss_curve_path, val_acc\n",
    "\n",
    "def evaluate_cnn(model_path, test_df, labels_list=['dog', 'cat'], name=\"cnn\", device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(CONFIG['resize_dim']),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    test_dataset = PetDataset(test_df, transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model = SimpleCNN().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1] # prob of class 1\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm_filename = f\"cm_{name}.png\"\n",
    "    plot_confusion_matrix(all_labels, all_preds, labels_list, f\"Confusion Matrix - {name}\", cm_filename)\n",
    "    \n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_filename = f\"roc_{name}.png\"\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, roc_filename))\n",
    "    plt.close()\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c8f0c62a563d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T11:52:57.732779107Z",
     "start_time": "2026-02-21T11:44:28.439568399Z"
    },
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.524593Z",
     "iopub.status.busy": "2026-02-22T11:46:35.524495Z",
     "iopub.status.idle": "2026-02-22T11:46:35.532839Z",
     "shell.execute_reply": "2026-02-22T11:46:35.532362Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(name, config_update):\n",
    "    print(f\"\\n--- Running Experiment: {name} ---\")\n",
    "\n",
    "    # Reload Config\n",
    "    cfg = CONFIG.copy()\n",
    "    cfg.update(config_update)\n",
    "\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        for k, v in cfg.items():\n",
    "            if isinstance(v, dict):\n",
    "                for sub_k, sub_v in v.items():\n",
    "                    mlflow.log_param(f\"{k}_{sub_k}\", sub_v)\n",
    "            else:\n",
    "                mlflow.log_param(k, v)\n",
    "\n",
    "        extractor = FeatureExtractor(cfg)\n",
    "        train_df, val_df, test_df = load_data()\n",
    "\n",
    "        # Process\n",
    "        t0 = time.time()\n",
    "        print(\"Extracting features...\")\n",
    "        x_train, y_train = extractor.process_dataset(train_df, is_test=False)\n",
    "        x_val, y_val = extractor.process_dataset(val_df, is_test=True)\n",
    "        x_test, y_test = extractor.process_dataset(test_df, is_test=True)\n",
    "        y_train = np.asarray(y_train).ravel()\n",
    "        y_val = np.asarray(y_val).ravel()\n",
    "        y_test = np.asarray(y_test).ravel()\n",
    "\n",
    "        best_params = train_svm_optuna(x_train, y_train, x_val, y_val, trials=10)\n",
    "        print(f\"Best params (SVM): {best_params}\")\n",
    "\n",
    "        best_clf = SVC(**best_params, probability=True)\n",
    "        best_clf.fit(x_train, y_train)\n",
    "        \n",
    "        # Save base SVM model\n",
    "        joblib.dump(best_clf, os.path.join(OUTPUT_DIR, f\"{name}_base_svm.pkl\"))\n",
    "\n",
    "        y_pred = best_clf.predict(x_test)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "        plot_confusion_matrix(y_test, y_pred, ['dog', 'cat'], f\"Confusion Matrix - {name}\", f\"cm_{name}.png\")\n",
    "\n",
    "        pca = PCA(n_components=0.95) # Keep 95% variance\n",
    "        x_train_pca = pca.fit_transform(x_train)\n",
    "        x_val_pca = pca.transform(x_val)\n",
    "        x_test_pca = pca.transform(x_test)\n",
    "        print(f\"PCA reduced dim from {x_train.shape[1]} to {x_train_pca.shape[1]}\")\n",
    "\n",
    "        # 1. SVM\n",
    "        best_params_svm = train_svm_optuna(x_train_pca, y_train, x_val_pca, y_val, trials=5)\n",
    "        best_clf_svm = SVC(**best_params_svm, probability=True)\n",
    "        best_clf_svm.fit(x_train_pca, y_train)\n",
    "        y_pred_svm = best_clf_svm.predict(x_test_pca)\n",
    "        acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "        print(f\"Accuracy (SVM + PCA): {acc_svm:.4f}\")\n",
    "        plot_confusion_matrix(y_test, y_pred_svm, ['dog', 'cat'], f\"Confusion Matrix - {name} (SVM)\", f\"cm_{name}_svm.png\")\n",
    "        plot_roc_curve(best_clf_svm, x_test_pca, y_test, ['dog', 'cat'], f\"roc_{name}_svm.png\")\n",
    "        joblib.dump(best_clf_svm, os.path.join(OUTPUT_DIR, f\"{name}_svm_pca.pkl\"))\n",
    "\n",
    "        # 2. Random Forest Video\n",
    "        best_params_rf = train_rf_optuna(x_train_pca, y_train, x_val_pca, y_val, trials=5)\n",
    "        best_clf_rf = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "        best_clf_rf.fit(x_train_pca, y_train)\n",
    "        y_pred_rf = best_clf_rf.predict(x_test_pca)\n",
    "        acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "        print(f\"Accuracy (RF): {acc_rf:.4f}\")\n",
    "        plot_confusion_matrix(y_test, y_pred_rf, ['dog', 'cat'], f\"Confusion Matrix - {name} (RF)\", f\"cm_{name}_rf.png\")\n",
    "        plot_roc_curve(best_clf_rf, x_test_pca, y_test, ['dog', 'cat'], f\"roc_{name}_rf.png\")\n",
    "        joblib.dump(best_clf_rf, os.path.join(OUTPUT_DIR, f\"{name}_rf_pca.pkl\"))\n",
    "\n",
    "        # 3. KNN Video\n",
    "        best_params_knn = train_knn_optuna(x_train_pca, y_train, x_val_pca, y_val, trials=5)\n",
    "        best_clf_knn = KNeighborsClassifier(**best_params_knn)\n",
    "        best_clf_knn.fit(x_train_pca, y_train)\n",
    "        y_pred_knn = best_clf_knn.predict(x_test_pca)\n",
    "        acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "        print(f\"Accuracy (KNN + PCA): {acc_knn:.4f}\")\n",
    "        plot_confusion_matrix(y_test, y_pred_knn, ['dog', 'cat'], f\"Confusion Matrix - {name} (KNN)\", f\"cm_{name}_knn.png\")\n",
    "        plot_roc_curve(best_clf_knn, x_test_pca, y_test, ['dog', 'cat'], f\"roc_{name}_knn.png\")\n",
    "        joblib.dump(best_clf_knn, os.path.join(OUTPUT_DIR, f\"{name}_knn_pca.pkl\"))\n",
    "        \n",
    "        # 4. CNN Mode\n",
    "        cnn_model_path, cnn_loss_path, cnn_val_acc = train_cnn(train_df, val_df)\n",
    "        acc_cnn = evaluate_cnn(cnn_model_path, test_df, name=f\"{name}_cnn\")\n",
    "        print(f\"Accuracy (CNN): {acc_cnn:.4f}\")\n",
    "        \n",
    "        mlflow.log_metric(\"acc_base_svm\", acc)\n",
    "        mlflow.log_metric(\"acc_svm_pca\", acc_svm)\n",
    "        mlflow.log_metric(\"acc_rf_pca\", acc_rf)\n",
    "        mlflow.log_metric(\"acc_knn_pca\", acc_knn)\n",
    "        mlflow.log_metric(\"acc_cnn\", acc_cnn)\n",
    "        mlflow.log_artifacts(OUTPUT_DIR)\n",
    "\n",
    "        return {\n",
    "            'acc': acc,\n",
    "            'acc_svm': acc_svm,\n",
    "            'acc_rf': acc_rf,\n",
    "            'acc_knn': acc_knn,\n",
    "            'acc_cnn': acc_cnn\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8e6b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-22T11:46:35.534556Z",
     "iopub.status.busy": "2026-02-22T11:46:35.534451Z",
     "iopub.status.idle": "2026-02-22T11:48:30.713638Z",
     "shell.execute_reply": "2026-02-22T11:48:30.713158Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/22 17:16:36 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/22 17:16:36 INFO mlflow.store.db.utils: Updating database tables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/22 17:16:37 INFO mlflow.tracking.fluent: Experiment with name 'Dogs_vs_Cats' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main...\n",
      "\n",
      "--- Running Experiment: baseline_uniform_minmax ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Processing 1000 images with -1 jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (1000, 77)\n",
      "Df columms: Index(['image_id', 'encoded_label', 'red_0', 'red_1', 'red_2', 'red_3',\n",
      "       'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0',\n",
      "       'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7',\n",
      "       'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3',\n",
      "       'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9',\n",
      "       'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean',\n",
      "       'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std',\n",
      "       'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue',\n",
      "       'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean',\n",
      "       'glcm_dissimilarity_std', 'glcm_homogeneity_mean',\n",
      "       'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std',\n",
      "       'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1',\n",
      "       'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9',\n",
      "       'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area',\n",
      "       'contour_0_circularity', 'contour_1_area', 'contour_1_circularity',\n",
      "       'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std',\n",
      "       'hog_max'],\n",
      "      dtype='object')\n",
      "Feature names: ['red_0', 'red_1', 'red_2', 'red_3', 'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0', 'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7', 'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3', 'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9', 'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean', 'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std', 'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue', 'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean', 'glcm_dissimilarity_std', 'glcm_homogeneity_mean', 'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std', 'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1', 'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area', 'contour_0_circularity', 'contour_1_area', 'contour_1_circularity', 'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std', 'hog_max']\n",
      "Processing 200 images with -1 jobs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (200, 77)\n",
      "Df columms: Index(['image_id', 'encoded_label', 'red_0', 'red_1', 'red_2', 'red_3',\n",
      "       'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0',\n",
      "       'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7',\n",
      "       'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3',\n",
      "       'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9',\n",
      "       'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean',\n",
      "       'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std',\n",
      "       'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue',\n",
      "       'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean',\n",
      "       'glcm_dissimilarity_std', 'glcm_homogeneity_mean',\n",
      "       'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std',\n",
      "       'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1',\n",
      "       'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9',\n",
      "       'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area',\n",
      "       'contour_0_circularity', 'contour_1_area', 'contour_1_circularity',\n",
      "       'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std',\n",
      "       'hog_max'],\n",
      "      dtype='object')\n",
      "Feature names: ['red_0', 'red_1', 'red_2', 'red_3', 'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0', 'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7', 'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3', 'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9', 'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean', 'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std', 'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue', 'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean', 'glcm_dissimilarity_std', 'glcm_homogeneity_mean', 'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std', 'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1', 'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area', 'contour_0_circularity', 'contour_1_area', 'contour_1_circularity', 'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std', 'hog_max']\n",
      "Processing 200 images with -1 jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:10,328]\u001B[0m A new study created in memory with name: no-name-7a95e34e-f7d8-4182-a053-2c8cfd06c5be\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (200, 77)\n",
      "Df columms: Index(['image_id', 'encoded_label', 'red_0', 'red_1', 'red_2', 'red_3',\n",
      "       'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0',\n",
      "       'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7',\n",
      "       'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3',\n",
      "       'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9',\n",
      "       'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean',\n",
      "       'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std',\n",
      "       'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue',\n",
      "       'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean',\n",
      "       'glcm_dissimilarity_std', 'glcm_homogeneity_mean',\n",
      "       'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std',\n",
      "       'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1',\n",
      "       'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9',\n",
      "       'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area',\n",
      "       'contour_0_circularity', 'contour_1_area', 'contour_1_circularity',\n",
      "       'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std',\n",
      "       'hog_max'],\n",
      "      dtype='object')\n",
      "Feature names: ['red_0', 'red_1', 'red_2', 'red_3', 'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0', 'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7', 'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3', 'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9', 'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean', 'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std', 'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue', 'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean', 'glcm_dissimilarity_std', 'glcm_homogeneity_mean', 'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std', 'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1', 'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area', 'contour_0_circularity', 'contour_1_area', 'contour_1_circularity', 'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std', 'hog_max']\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:10,692]\u001B[0m Trial 0 finished with value: 0.6 and parameters: {'C': 0.014649863878224294, 'gamma': 0.19980662275478178, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:10,910]\u001B[0m Trial 1 finished with value: 0.65 and parameters: {'C': 6.823308970842741, 'gamma': 0.1689980437183544, 'kernel': 'rbf'}. Best is trial 1 with value: 0.65.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:10,998]\u001B[0m Trial 2 finished with value: 0.6 and parameters: {'C': 1.822007159890564, 'gamma': 0.002845051767219522, 'kernel': 'rbf'}. Best is trial 1 with value: 0.65.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:11,243]\u001B[0m Trial 3 finished with value: 0.645 and parameters: {'C': 26.232524697894608, 'gamma': 0.04196466396761505, 'kernel': 'rbf'}. Best is trial 1 with value: 0.65.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:11,328]\u001B[0m Trial 4 finished with value: 0.665 and parameters: {'C': 0.19404630670067408, 'gamma': 0.004489997135312739, 'kernel': 'rbf'}. Best is trial 4 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:14,250]\u001B[0m Trial 5 finished with value: 0.645 and parameters: {'C': 21.738681997971298, 'gamma': 0.01792556839155171, 'kernel': 'linear'}. Best is trial 4 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:14,357]\u001B[0m Trial 6 finished with value: 0.65 and parameters: {'C': 0.01763408780871105, 'gamma': 0.12211192233046861, 'kernel': 'poly'}. Best is trial 4 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:17,644]\u001B[0m Trial 7 finished with value: 0.655 and parameters: {'C': 24.275111631866388, 'gamma': 0.5861590170911523, 'kernel': 'linear'}. Best is trial 4 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:17,747]\u001B[0m Trial 8 finished with value: 0.65 and parameters: {'C': 0.23901377380176067, 'gamma': 0.1682213364083474, 'kernel': 'linear'}. Best is trial 4 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:17,874]\u001B[0m Trial 9 finished with value: 0.645 and parameters: {'C': 0.6123462300434388, 'gamma': 0.4216902535314744, 'kernel': 'linear'}. Best is trial 4 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:18,070]\u001B[0m A new study created in memory with name: no-name-c8b69d02-60f0-45b1-afaa-b9d70555d350\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 0.19404630670067408, 'gamma': 0.004489997135312739, 'kernel': 'rbf'}\n",
      "Best params (SVM): {'C': 0.19404630670067408, 'gamma': 0.004489997135312739, 'kernel': 'rbf'}\n",
      "Accuracy: 0.6200\n",
      "PCA reduced dim from 75 to 32\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:18,177]\u001B[0m Trial 0 finished with value: 0.655 and parameters: {'C': 0.09670919015437962, 'gamma': 4.143248457816081, 'kernel': 'rbf'}. Best is trial 0 with value: 0.655.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:18,267]\u001B[0m Trial 1 finished with value: 0.585 and parameters: {'C': 0.013773676264905627, 'gamma': 1.0632124324320558, 'kernel': 'poly'}. Best is trial 0 with value: 0.655.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:18,351]\u001B[0m Trial 2 finished with value: 0.6 and parameters: {'C': 5.430641802858907, 'gamma': 0.0014811242933749494, 'kernel': 'rbf'}. Best is trial 0 with value: 0.655.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:18,543]\u001B[0m Trial 3 finished with value: 0.63 and parameters: {'C': 71.625630626432, 'gamma': 0.012686566765775235, 'kernel': 'rbf'}. Best is trial 0 with value: 0.655.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:18,673]\u001B[0m Trial 4 finished with value: 0.58 and parameters: {'C': 0.17449539081652335, 'gamma': 0.9665373996680331, 'kernel': 'poly'}. Best is trial 0 with value: 0.655.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 0.09670919015437962, 'gamma': 4.143248457816081, 'kernel': 'rbf'}\n",
      "Accuracy (SVM + PCA): 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:18,928]\u001B[0m A new study created in memory with name: no-name-fb482e06-57d5-4fd7-be23-23bc1318104f\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,026]\u001B[0m Trial 0 finished with value: 0.635 and parameters: {'n_estimators': 152, 'max_depth': 50, 'min_samples_split': 13, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.635.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,139]\u001B[0m Trial 1 finished with value: 0.65 and parameters: {'n_estimators': 195, 'max_depth': 45, 'min_samples_split': 13, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.65.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,275]\u001B[0m Trial 2 finished with value: 0.665 and parameters: {'n_estimators': 285, 'max_depth': 44, 'min_samples_split': 13, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,370]\u001B[0m Trial 3 finished with value: 0.66 and parameters: {'n_estimators': 167, 'max_depth': 48, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,456]\u001B[0m Trial 4 finished with value: 0.655 and parameters: {'n_estimators': 170, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.665.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (RF): {'n_estimators': 285, 'max_depth': 44, 'min_samples_split': 13, 'min_samples_leaf': 7}\n",
      "Accuracy (RF): 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,706]\u001B[0m A new study created in memory with name: no-name-a05c4aa5-0cc3-466b-abbe-69920ef95c2c\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,735]\u001B[0m Trial 0 finished with value: 0.63 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 0 with value: 0.63.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,738]\u001B[0m Trial 1 finished with value: 0.63 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 0 with value: 0.63.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,741]\u001B[0m Trial 2 finished with value: 0.615 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 0 with value: 0.63.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,744]\u001B[0m Trial 3 finished with value: 0.65 and parameters: {'n_neighbors': 18, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 3 with value: 0.65.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:17:19,747]\u001B[0m Trial 4 finished with value: 0.64 and parameters: {'n_neighbors': 17, 'weights': 'distance', 'metric': 'euclidean'}. Best is trial 3 with value: 0.65.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing KNN...\n",
      "Best params (KNN): {'n_neighbors': 18, 'weights': 'uniform', 'metric': 'euclidean'}\n",
      "Accuracy (KNN + PCA): 0.6550\n",
      "Training CNN on cuda...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 1.1398, Val Loss: 0.6991, Val Acc: 0.4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 0.6806, Val Loss: 0.6672, Val Acc: 0.5850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.6006, Val Loss: 0.6229, Val Acc: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.4880, Val Loss: 0.6166, Val Acc: 0.6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.3063, Val Loss: 0.8584, Val Acc: 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CNN): 0.6550\n",
      "\n",
      "--- Running Experiment: uniform_stdscaler ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Processing 1000 images with -1 jobs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (1000, 77)\n",
      "Df columms: Index(['image_id', 'encoded_label', 'red_0', 'red_1', 'red_2', 'red_3',\n",
      "       'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0',\n",
      "       'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7',\n",
      "       'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3',\n",
      "       'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9',\n",
      "       'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean',\n",
      "       'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std',\n",
      "       'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue',\n",
      "       'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean',\n",
      "       'glcm_dissimilarity_std', 'glcm_homogeneity_mean',\n",
      "       'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std',\n",
      "       'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1',\n",
      "       'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9',\n",
      "       'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area',\n",
      "       'contour_0_circularity', 'contour_1_area', 'contour_1_circularity',\n",
      "       'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std',\n",
      "       'hog_max'],\n",
      "      dtype='object')\n",
      "Feature names: ['red_0', 'red_1', 'red_2', 'red_3', 'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0', 'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7', 'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3', 'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9', 'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean', 'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std', 'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue', 'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean', 'glcm_dissimilarity_std', 'glcm_homogeneity_mean', 'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std', 'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1', 'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area', 'contour_0_circularity', 'contour_1_area', 'contour_1_circularity', 'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std', 'hog_max']\n",
      "Processing 200 images with -1 jobs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (200, 77)\n",
      "Df columms: Index(['image_id', 'encoded_label', 'red_0', 'red_1', 'red_2', 'red_3',\n",
      "       'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0',\n",
      "       'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7',\n",
      "       'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3',\n",
      "       'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9',\n",
      "       'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean',\n",
      "       'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std',\n",
      "       'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue',\n",
      "       'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean',\n",
      "       'glcm_dissimilarity_std', 'glcm_homogeneity_mean',\n",
      "       'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std',\n",
      "       'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1',\n",
      "       'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9',\n",
      "       'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area',\n",
      "       'contour_0_circularity', 'contour_1_area', 'contour_1_circularity',\n",
      "       'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std',\n",
      "       'hog_max'],\n",
      "      dtype='object')\n",
      "Feature names: ['red_0', 'red_1', 'red_2', 'red_3', 'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0', 'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7', 'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3', 'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9', 'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean', 'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std', 'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue', 'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean', 'glcm_dissimilarity_std', 'glcm_homogeneity_mean', 'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std', 'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1', 'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area', 'contour_0_circularity', 'contour_1_area', 'contour_1_circularity', 'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std', 'hog_max']\n",
      "Processing 200 images with -1 jobs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:04,105]\u001B[0m A new study created in memory with name: no-name-b40121dc-836a-4ab9-974f-f6a351d44f88\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (200, 77)\n",
      "Df columms: Index(['image_id', 'encoded_label', 'red_0', 'red_1', 'red_2', 'red_3',\n",
      "       'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0',\n",
      "       'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7',\n",
      "       'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3',\n",
      "       'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9',\n",
      "       'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean',\n",
      "       'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std',\n",
      "       'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue',\n",
      "       'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean',\n",
      "       'glcm_dissimilarity_std', 'glcm_homogeneity_mean',\n",
      "       'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std',\n",
      "       'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1',\n",
      "       'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9',\n",
      "       'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area',\n",
      "       'contour_0_circularity', 'contour_1_area', 'contour_1_circularity',\n",
      "       'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std',\n",
      "       'hog_max'],\n",
      "      dtype='object')\n",
      "Feature names: ['red_0', 'red_1', 'red_2', 'red_3', 'red_4', 'red_5', 'red_6', 'red_7', 'red_8', 'red_9', 'blue_0', 'blue_1', 'blue_2', 'blue_3', 'blue_4', 'blue_5', 'blue_6', 'blue_7', 'blue_8', 'blue_9', 'green_0', 'green_1', 'green_2', 'green_3', 'green_4', 'green_5', 'green_6', 'green_7', 'green_8', 'green_9', 'moments_h_mean', 'moments_h_std', 'moments_skew_h', 'moments_s_mean', 'moments_s_std', 'moments_skew_s', 'moments_v_mean', 'moments_v_std', 'moments_skew_v', 'avg_red', 'avg_green', 'avg_blue', 'glcm_contrast_mean', 'glcm_contrast_std', 'glcm_dissimilarity_mean', 'glcm_dissimilarity_std', 'glcm_homogeneity_mean', 'glcm_homogeneity_std', 'glcm_correlation_mean', 'glcm_correlation_std', 'glcm_energy_mean', 'glcm_energy_std', 'glcm_entropy', 'lbp_0', 'lbp_1', 'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'gabor_mean', 'gabor_std', 'canny_edge_density', 'contour_0_area', 'contour_0_circularity', 'contour_1_area', 'contour_1_circularity', 'contour_2_area', 'contour_2_circularity', 'hog_mean', 'hog_std', 'hog_max']\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:06,477]\u001B[0m Trial 0 finished with value: 0.66 and parameters: {'C': 0.3702907082187756, 'gamma': 0.43500063276753886, 'kernel': 'linear'}. Best is trial 0 with value: 0.66.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:07,580]\u001B[0m Trial 1 finished with value: 0.66 and parameters: {'C': 0.19843844848823267, 'gamma': 0.007717709261645421, 'kernel': 'linear'}. Best is trial 0 with value: 0.66.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:09,185]\u001B[0m Trial 2 finished with value: 0.67 and parameters: {'C': 0.26145632393529983, 'gamma': 0.0015757449456490441, 'kernel': 'linear'}. Best is trial 2 with value: 0.67.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:09,599]\u001B[0m Trial 3 finished with value: 0.595 and parameters: {'C': 0.5628757191550531, 'gamma': 0.27916473834139865, 'kernel': 'poly'}. Best is trial 2 with value: 0.67.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:09,752]\u001B[0m Trial 4 finished with value: 0.66 and parameters: {'C': 2.626413610008803, 'gamma': 0.006177404047498, 'kernel': 'rbf'}. Best is trial 2 with value: 0.67.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:10,170]\u001B[0m Trial 5 finished with value: 0.57 and parameters: {'C': 6.539563825846515, 'gamma': 1.6393435066088682, 'kernel': 'poly'}. Best is trial 2 with value: 0.67.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:10,295]\u001B[0m Trial 6 finished with value: 0.445 and parameters: {'C': 0.01998188027007326, 'gamma': 7.558743766701275, 'kernel': 'rbf'}. Best is trial 2 with value: 0.67.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:10,404]\u001B[0m Trial 7 finished with value: 0.59 and parameters: {'C': 0.06826291506697482, 'gamma': 0.012188830080453775, 'kernel': 'poly'}. Best is trial 2 with value: 0.67.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:10,827]\u001B[0m Trial 8 finished with value: 0.605 and parameters: {'C': 0.05198864846796337, 'gamma': 5.811294878096245, 'kernel': 'poly'}. Best is trial 2 with value: 0.67.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:11,240]\u001B[0m Trial 9 finished with value: 0.575 and parameters: {'C': 0.07581846822376925, 'gamma': 0.2665563917979947, 'kernel': 'poly'}. Best is trial 2 with value: 0.67.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 0.26145632393529983, 'gamma': 0.0015757449456490441, 'kernel': 'linear'}\n",
      "Best params (SVM): {'C': 0.26145632393529983, 'gamma': 0.0015757449456490441, 'kernel': 'linear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:13,186]\u001B[0m A new study created in memory with name: no-name-2b071a53-7f60-49a0-a53f-c0aff7250bba\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6850\n",
      "PCA reduced dim from 75 to 34\n",
      "Optimizing SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:13,298]\u001B[0m Trial 0 finished with value: 0.455 and parameters: {'C': 0.011683675312674481, 'gamma': 0.5162481301525969, 'kernel': 'rbf'}. Best is trial 0 with value: 0.455.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:13,796]\u001B[0m Trial 1 finished with value: 0.55 and parameters: {'C': 0.07436654697637819, 'gamma': 0.10357314302503824, 'kernel': 'poly'}. Best is trial 1 with value: 0.55.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:14,388]\u001B[0m Trial 2 finished with value: 0.545 and parameters: {'C': 7.232124920785115, 'gamma': 5.439050860989891, 'kernel': 'poly'}. Best is trial 1 with value: 0.55.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:14,985]\u001B[0m Trial 3 finished with value: 0.555 and parameters: {'C': 38.020785137326754, 'gamma': 0.33299764069760124, 'kernel': 'poly'}. Best is trial 3 with value: 0.555.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:15,104]\u001B[0m Trial 4 finished with value: 0.575 and parameters: {'C': 2.1941092494290237, 'gamma': 0.005920505165441615, 'kernel': 'poly'}. Best is trial 4 with value: 0.575.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (SVM): {'C': 2.1941092494290237, 'gamma': 0.005920505165441615, 'kernel': 'poly'}\n",
      "Accuracy (SVM + PCA): 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:15,328]\u001B[0m A new study created in memory with name: no-name-26bcf92c-bf37-48a1-8d58-c4eb9796a7ef\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:15,467]\u001B[0m Trial 0 finished with value: 0.6 and parameters: {'n_estimators': 245, 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.6.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:15,545]\u001B[0m Trial 1 finished with value: 0.635 and parameters: {'n_estimators': 198, 'max_depth': 7, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.635.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:15,631]\u001B[0m Trial 2 finished with value: 0.625 and parameters: {'n_estimators': 195, 'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 8}. Best is trial 1 with value: 0.635.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:15,733]\u001B[0m Trial 3 finished with value: 0.64 and parameters: {'n_estimators': 216, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.64.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:15,815]\u001B[0m Trial 4 finished with value: 0.6 and parameters: {'n_estimators': 216, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.64.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (RF): {'n_estimators': 216, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 8}\n",
      "Accuracy (RF): 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:16,048]\u001B[0m A new study created in memory with name: no-name-81d1dcbc-9a36-4a1f-a5d9-561a47a194ec\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:16,052]\u001B[0m Trial 0 finished with value: 0.64 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 0 with value: 0.64.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:16,055]\u001B[0m Trial 1 finished with value: 0.66 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 1 with value: 0.66.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:16,058]\u001B[0m Trial 2 finished with value: 0.645 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'metric': 'euclidean'}. Best is trial 1 with value: 0.66.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:16,061]\u001B[0m Trial 3 finished with value: 0.635 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 1 with value: 0.66.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2026-02-22 17:18:16,064]\u001B[0m Trial 4 finished with value: 0.56 and parameters: {'n_neighbors': 20, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 1 with value: 0.66.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing KNN...\n",
      "Best params (KNN): {'n_neighbors': 12, 'weights': 'uniform', 'metric': 'manhattan'}\n",
      "Accuracy (KNN + PCA): 0.6800\n",
      "Training CNN on cuda...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 1.4567, Val Loss: 0.6970, Val Acc: 0.4450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 0.6708, Val Loss: 0.6925, Val Acc: 0.5700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.5904, Val Loss: 0.6126, Val Acc: 0.6600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.4143, Val Loss: 0.7033, Val Acc: 0.6200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.2109, Val Loss: 0.7555, Val Acc: 0.6300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CNN): 0.6400\n",
      "\n",
      "--- Summary ---\n",
      "Baseline (Voting): 0.62\n",
      "Baseline (SVM Agg): 0.59\n",
      "Baseline (RF Agg): 0.655\n",
      "Baseline (KNN Agg): 0.655\n",
      "\n",
      "StdScaler (Voting): 0.685\n",
      "StdScaler (SVM Agg): 0.625\n",
      "StdScaler (RF Agg): 0.675\n",
      "StdScaler (KNN Agg): 0.68\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mlflow.set_experiment(\"Dogs_vs_Cats\")\n",
    "    print(\"Starting main...\")\n",
    "    # 1. Baseline: Uniform Sampling, MinMax\n",
    "    res_baseline = run_experiment('baseline_uniform_minmax', {\n",
    "        'normalization': 'minmax'\n",
    "    })\n",
    "\n",
    "    # 2. Improved: Uniform, StandardScaler (Req 3)\n",
    "    res_std = run_experiment('uniform_stdscaler', {\n",
    "        'normalization': 'standard'\n",
    "    })\n",
    "\n",
    "\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    print(\"Baseline SVM without PCA Accuracy:\", res_baseline['acc'])\n",
    "    print(\"Baseline (SVM with PCA) Accuracy:\", res_baseline['acc_svm'])\n",
    "    print(\"Baseline (RF with PCA) Accuracy:\", res_baseline['acc_rf'])\n",
    "    print(\"Baseline (KNN with PCA) Accuracy:\", res_baseline['acc_knn'])\n",
    "    print(\"Baseline (CNN with PCA) Accuracy:\", res_baseline['acc_cnn'])\n",
    "\n",
    "    print(\"\\nStdScaler SVM without PCA Accuracy:\", res_std['acc'])\n",
    "    print(\"StdScaler (SVM with PCA) Accuracy:\", res_std['acc_svm'])\n",
    "    print(\"StdScaler (RF with PCA) Accuracy:\", res_std['acc_rf'])\n",
    "    print(\"StdScaler (KNN with PCA) Accuracy:\", res_std['acc_knn'])\n",
    "    print(\"StdScaler (CNN with PCA) Accuracy:\", res_std['acc_cnn'])\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()\n",
    "    print(f\"CRITICAL ERROR: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
